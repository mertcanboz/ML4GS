{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"attacks.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNet3XyEVu+vzqKqdaf9SrZ"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"86B1kwyxn5wL","colab_type":"code","colab":{}},"source":["import torch\n","\n","\n","def fast_gradient_attack(logits: torch.Tensor, x: torch.Tensor, y: torch.Tensor, epsilon: float, norm: str = \"2\",\n","                         loss_fn=torch.nn.functional.cross_entropy):\n","    \"\"\"\n","    Perform a single-step projected gradient attack on the input x.\n","    Parameters\n","    ----------\n","    logits: torch.Tensor of shape [B, K], where B is the batch size and K is the number of classes.\n","        The logits for each sample in the batch.\n","    x: torch.Tensor of shape [B, C, N, N], where B is the batch size, C is the number of channels, and N is the image\n","       dimension.\n","       The input batch of images. Note that x.requires_grad must have been active before computing the logits\n","       (otherwise will throw ValueError).\n","    y: torch.Tensor of shape [B, 1]\n","        The labels of the input batch of images.\n","    epsilon: float\n","        The desired strength of the perturbation. That is, the perturbation (before clipping) will have a norm of\n","        exactly epsilon as measured by the desired norm (see argument: norm).\n","    norm: str, can be [\"1\", \"2\", \"inf\"]\n","        The norm with which to measure the perturbation. E.g., when norm=\"1\", the perturbation (before clipping)\n","         will have a L_1 norm of exactly epsilon (see argument: epsilon).\n","    loss_fn: function\n","        The loss function used to construct the attack. By default, this is simply the cross entropy loss.\n","\n","    Returns\n","    -------\n","    torch.Tensor of shape [B, C, N, N]: the perturbed input samples.\n","\n","    \"\"\"\n","    norm = str(norm)\n","    assert norm in [\"1\", \"2\", \"inf\"]\n","\n","##########################################################\n","    # YOUR CODE HERE\n","    loss_fn(logits, y).backward()\n","    x_pert = torch.Tensor(x.shape)\n","\n","    if(norm == \"inf\"):\n","        # print('linf')\n","        # implementation based on Eq. (1) https://arxiv.org/pdf/1705.03387.pdf\n","        # adversarial perturbation = epsilon * sign(gradient)\n","        perturbed_image = x + epsilon * x.grad.data.sign()\n","        x_pert = torch.clamp(perturbed_image, 0, 1.0) # return grey scale image, if x < 0 return 0; if x > 1 return 1; else return x\n","\n","    if(norm == \"2\"):\n","        # print('l2')\n","        # implementation based on Eq. (3) https://arxiv.org/pdf/1705.03387.pdf\n","        # adversarial perturbation = epsilon * gradient/||gradient||_2\n","        size = x.shape[1] * x.shape[2] * x.shape[3]\n","        # simple implementation\n","        # print('with 1')\n","        # epsilon = epsilon / torch.sqrt(torch.FloatTensor([size])).item()\n","        # perturbed_image = x + epsilon * x.grad.data.sign()\n","        norm_2 = x.grad.data.square().sum(dim = (1,2,3)).sqrt()\n","        norm_2 = norm_2 * torch.ones([x.shape[0], size]).t()\n","        norm_2 = norm_2.t().reshape(x.shape)\n","        perturbed_image = x + epsilon * x.grad.data / norm_2\n","        x_pert = torch.clamp(perturbed_image, 0, 1.0)\n","    ##########################################################\n","\n","    return x_pert.detach()"],"execution_count":0,"outputs":[]}]}