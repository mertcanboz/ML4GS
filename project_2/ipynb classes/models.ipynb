{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"models.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOifob+uLkz/oWM9fNt6Evt"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"UZUQnQIws4_P","colab_type":"code","outputId":"3c33dc05-cd81-4ba1-b4ed-22ced43151ea","executionInfo":{"status":"ok","timestamp":1591280766249,"user_tz":-120,"elapsed":3464,"user":{"displayName":"Clara Leung","photoUrl":"","userId":"02206143411713870524"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"source":["from math import ceil\n","from typing import Tuple\n","\n","import torch\n","from scipy.stats import norm, binom_test\n","from torch import nn\n","from statsmodels.stats.proportion import proportion_confint\n","\n","\n","class ConvNN(nn.Module):\n","    \"\"\"\n","    A simple convolutional neural network for image classification on MNIST.\n","    \"\"\"\n","\n","    def __init__(self):\n","        super(ConvNN, self).__init__()\n","        self.sequential = nn.Sequential(\n","                             nn.Conv2d(1, 5, 5),\n","                             nn.ReLU(),\n","                             nn.BatchNorm2d(5),\n","                             nn.MaxPool2d(2),\n","                             nn.Conv2d(5, 5, 5),\n","                             nn.ReLU(),\n","                             nn.MaxPool2d(2),\n","                             nn.Flatten(),\n","                             nn.Linear(80, 10),\n","                            )\n","\n","    def forward(self, input):\n","        assert input.min() >= 0 and input.max() <= 1.\n","        return self.sequential(input)\n","\n","    def device(self):\n","        \"\"\"\n","        Convenience function returning the device the model is located on.\n","        \"\"\"\n","        return next(self.parameters()).device\n","\n","\n","def lower_confidence_bound(num_class_A: int, num_samples: int, alpha: float) -> float:\n","    \"\"\"\n","    Computes a lower bound on the probability of the event occuring in a Bernoulli distribution.\n","    Parameters\n","    ----------\n","    num_class_A: int\n","        The number of times the event occured in the samples.\n","    num_samples: int\n","        The total number of samples from the bernoulli distribution.\n","    alpha: float\n","        The desired confidence level, e.g. 0.05.\n","\n","    Returns\n","    -------\n","    lower_bound: float\n","        The lower bound on the probability of the event occuring in a Bernoulli distribution.\n","\n","    \"\"\"\n","    return proportion_confint(num_class_A, num_samples, alpha=2 * alpha, method=\"beta\")[0]\n","\n","\n","class SmoothClassifier(nn.Module):\n","    \"\"\"\n","    Randomized smoothing classifier.\n","    \"\"\"\n","\n","    # to abstain, Smooth returns this int\n","    ABSTAIN = -1\n","\n","    def __init__(self, base_classifier: nn.Module, num_classes: int, sigma: float):\n","        \"\"\"\n","        Constructor for SmoothClassifier.\n","        Parameters\n","        ----------\n","        base_classifier: nn.Module\n","            The base classifier (i.e. f(x)) that maps an input sample to a logit vector.\n","        num_classes: int\n","            The number of classes.\n","        sigma: float\n","            The variance used for the Gaussian perturbations.\n","        \"\"\"\n","        super(SmoothClassifier, self).__init__()\n","        self.base_classifier = base_classifier\n","        self.num_classes = num_classes\n","        self.sigma = sigma\n","\n","    def device(self):\n","        return self.base_classifier.device()\n","\n","    def certify(self, inputs: torch.Tensor, n0: int, num_samples: int, alpha: float, batch_size: int) -> Tuple[int,\n","                                                                                                               float]:\n","        \"\"\"\n","        Certify the input sample using randomized smoothing.\n","\n","        Uses lower_confidence_bound to get a lower bound on p_A, the probability of the top class.\n","\n","        Parameters\n","        ----------\n","        inputs: torch.Tensor of shape [1, C, N, N], where C is the number of channels and N is the image width/height.\n","            The input image to certify.\n","        n0: int\n","            Number of samples to determine the most likely class.\n","        num_samples: int\n","            Number of samples to use for the robustness certification.\n","        alpha: float\n","            The confidence level, e.g. 0.05 for an expected error rate of 5%.\n","        batch_size: int\n","           The batch size to use during the certification, i.e. how many noise samples to classify in parallel.\n","\n","        Returns\n","        -------\n","        Tuple containing:\n","            * top_class: int. The predicted class g(x) of the input sample x. Returns -1 in case the classifier abstains\n","                         because the desired confidence level could not be reached.\n","            * radius: float. The radius for which the prediction can be certified. Is zero in case the classifier\n","                      abstains.\n","\n","        \"\"\"\n","        self.base_classifier.eval()\n","\n","        ##########################################################\n","        # YOUR CODE HERE\n","        # Lecture robustness p.96\n","        # Step 1: Determine the most likely class, i.e. using a small set of samples we first take a guess at top_class\n","        # get inputs with noises sample N(inputs, sigma^2), i.e x = inputs + epsilon\n","        class_counts_with_small_sample = self._sample_noise_predictions(inputs, n0, batch_size).cpu()\n","        top_class = toech.argmax(class_counts_with_small_sample).item()\n","\n","        # Step 2: Determine p_A_lower_bound using a large set of samples based on the confidence interval\n","        # Monte Carlo estimation: sample a large number of samples from the Gaussian to estimate p_A\n","        class_counts_with_monte_carlo = self._sample_noise_predictions(inputs, num_samples, batch_size).cpu()\n","        num_class_A = class_counts_with_monte_carlo[top_class].item()\n","        p_A_lower_bound = lower_confidence_bound(num_class_A, num_samples, alpha)\n","        ##########################################################\n","\n","        if p_A_lower_bound < 0.5:\n","            return SmoothClassifier.ABSTAIN, 0.0\n","        else:\n","            ##########################################################\n","            # YOUR CODE HERE\n","            radius = self.sigma * norm.ppf(p_A_lower_bound) # Percent point function (inverse of cdf) at q of the given RV.\n","                                                            # q = p_A_lower_bound, i.e. lower tail probability\n","            ##########################################################\n","            return top_class, radius\n","\n","    def predict(self, inputs: torch.tensor, num_samples: int, alpha: float, batch_size: int) -> int:\n","        \"\"\"\n","        Predict a label for the input sample via the smooth classifier g(x).\n","\n","        Uses the test binom_test(count1, count1+count2, p=0.5) > alpha to determine whether the top class is the winning\n","        class with at least the confidence level alpha.\n","\n","        Parameters\n","        ----------\n","        inputs: torch.Tensor of shape [1, C, N, N], where C is the number of channels and N is the image width/height.\n","            The input image to predict.\n","        num_samples: int\n","            The number of samples to draw in order to determine the most likely class.\n","        alpha: float\n","            The desired confidence level that the top class is indeed the most likely class. E.g. alpha=0.05 means that\n","            the expected error rate must not be larger than 5%.\n","        batch_size: int\n","            The batch si ze to use during the prediction, i.e. how many noise samples to classify in parallel.\n","\n","        Returns\n","        -------\n","        int: the winning class or -1 in case the desired confidence level could not be reached.\n","        \"\"\"\n","        self.base_classifier.eval()\n","        class_counts = self._sample_noise_predictions(inputs, num_samples, batch_size).cpu()\n","        ##########################################################\n","        # YOUR CODE HERE\n","        top_2_classes = torch.argsort(class_counts, descending=True)[:2]\n","        print(top_2_classes)\n","        count1 = class_counts[top_2_classes[0]]\n","        count2 = class_counts[top_2_classes[1]]\n","        if binom_test(count1, count1 + count2, p=0.5) > alpha:\n","          return self.ABSTAIN\n","        else:\n","          return top_2_classes[0]\n","        ##########################################################\n","\n","    def _sample_noise_predictions(self, inputs: torch.tensor, num_samples: int, batch_size: int) -> torch.Tensor:\n","        \"\"\"\n","        Sample random noise perturbations for the input sample and count the predicted classes of the base classifier.\n","\n","        Note: this function clamps the distorted samples in the valid range, i.e. [0,1].\n","\n","        Parameters\n","        ----------\n","        inputs: torch.Tensor of shape [1, C, N, N], where C is the number of channels and N is the image width/height.\n","            The input image to predict.\n","        num_samples: int\n","            The number of samples to draw.\n","        batch_size: int\n","            The batch size to use during the prediction, i.e. how many noise samples to classify in parallel.\n","\n","        Returns\n","        -------\n","        torch.Tensor of shape [K,], where K is the number of classes.\n","        Each entry of the tensor contains the number of times the base classifier predicted the corresponding class for\n","        the noise samples.\n","        \"\"\"\n","        num_remaining = num_samples\n","        with torch.no_grad():\n","            classes = torch.arange(self.num_classes).to(self.device())\n","            class_counts = torch.zeros([self.num_classes], dtype=torch.long, device=self.device())\n","            for it in range(ceil(num_samples / batch_size)):\n","                this_batch_size = min(num_remaining, batch_size)\n","                ##########################################################\n","                # YOUR CODE HERE\n","                num_remaining -= this_batch_size\n","\n","                x = inputs.repeat((this_batch_size, 1, 1, 1))\n","                # x = inputs.flatten()\n","                # x = inputs.view(-1)\n","                noise = torch.randn_like(x) * self.sigma\n","                # noise = norm.rsv(loc=x, scale=self.sigma, size=this_batch_size)\n","                preds = torch.argmax(self.base_classifier(x + noise), dim=1)\n","                preds = preds.cpu().numpy()\n","                for i in preds:\n","                  class_counts[i] += 1\n","\n","                print()\n","                print(class_counts)\n","                ##########################################################\n","        return class_counts\n","\n","    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n","        \"\"\"\n","        Make a single prediction for the input batch using the base classifier and random Gaussian noise.\n","\n","        Note: this function clamps the distorted samples in the valid range, i.e. [0,1].\n","        Parameters\n","        ----------\n","        inputs: torch.Tensor of shape [B, C, N, N], where B is the batch size, C is the number of channels,\n","               and N is the image width/height.\n","            The input batch of images to predict.\n","        Returns\n","        -------\n","        torch.Tensor of shape [B, K]\n","        The logits for each input image.\n","        \"\"\"\n","        noise = torch.randn_like(inputs) * self.sigma\n","        return self.base_classifier((inputs + noise).clamp(0, 1))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"],"name":"stderr"}]}]}